library(mirt)
lvl1 <- c('Strongly disagree'=1, 'Disagree'=2, 'Neither agree nor disagree'=3, 'Agree'=4,
'Strongly agree'=5)
master1 <- likert2int(master1,levels = lvl1)
View(master1)
dim(master1)
##outliers using Malahanobis distance
cutoff = qchisq(1-.001, ncol(master1))
mahal = mahalanobis(master1,
colMeans(master1),
cov(master1))
mahal
cutoff ##cutoff score
ncol(master1) ##df
summary(mahal < cutoff)
##exclude outliers
noout1 = subset(master1, mahal < cutoff)
summary(noout1)
##running the efa analysis
library(psych)
library(GPArotation)
##additivity - option 1(Correlation)
correl = cor(noout1, use = "pairwise.complete.obs")
symnum(correl)
correl
##correlation adequacy Bartlett's test
cortest.bartlett(correl, n = nrow(noout1))
##sampling adequacy KMO test
KMO(correl)
##Overall MSA =  0.95 meaning
##that there are a significant number of factors in the dataset
#close to 1 which is better
##how many factors?
##how many factors?
# fm: What factor method to use.
# fm: minres, ml, uls, wls, gls, pa
# fa: show the eigen values for a principal components
# fa: you can have fa or pc, or both
nofactors = fa.parallel(noout1, fm="ml", fa="fa")
sum(nofactors$fa.values > 1.0) ##old kaiser criterion
sum(nofactors$fa.values > .7) ##new kaiser criterion
##simple structure with a two factor model
round1 = fa(noout1, nfactors=2, rotate = "oblimin", fm = "ml")
round1 #save the loading data into an excel file and check high correlation and similar correlation
#drop items that have similar correlations
#diagram
fa.diagram(round1)
round1$loadings
#Dropping variables based on communality score
drop <- c("q18b","q20b","q20d","q50b","q50c","q50d","q50h","q62f","q62i","q79b","q79c")
noout = noout1[,!(names(noout1) %in% drop)]
round2 = fa(noout1, nfactors=2, rotate = "oblimin", fm = "ml")
round2
fa.diagram(round2)
##import the file
df1 <- read.csv("C:/Users/karishma/Downloads/2014-aps-employee-census-5-point-dataset.csv")
View(df)
summary(df)
#Selecting only leadership style questions
library(dplyr)
master1 <- dplyr::select(df1,"q6","q18b","q20a","q20b","q20c","q20d","q20e","q20f","q20g","q21a","q21b","q21c","q21d","q21e","q21f","q21j","q50b","q50c","q50d","q50h","q52a","q62f","q62i","q79b","q79c")
View(master1)
master1 <-filter(master1, q6 == "Trainee/Graduate/APS")
View(master1)
str(master1)
# replace blank with NA
master1[master1 == " "] <- NA
##accuracy
summary(master1)
library(dlookr)
diagnose(master1)
##exclude the participant missing too much data
percentmissing = function (x){ sum(is.na(x))/length(x) * 100}
master1 = subset(master1, missing <= 5)
#Return subsets data frames which meet conditions.
##make sure the columns aren't missing too much
apply(master1, 2, percentmissing)
##impute missing data using mode function
my_mode <- function(x) {
unique_x <- unique(x)
mode <- unique_x[which.max(tabulate(match(x, unique_x)))]
mode
}
master1<-master1%>%
mutate_if(is.character, function(x) ifelse(is.na(x), my_mode(x), x))
#Dropping q52a since it has more than 65% missing data
drop <- c("q52a")
master1 = master1[,!(names(master1) %in% drop)]
#Verifying missing values
library(dplyr)
diagnose(master1)
##make sure the columns aren't missing too much
apply(master1, 2, percentmissing)
dim(master1)
#Dropping q6 since it was added to
drop <- c("q6")
master1 = master1[,!(names(master1) %in% drop)]
dim(master)
#likert scale conversion
library(mirt)
lvl1 <- c('Strongly disagree'=1, 'Disagree'=2, 'Neither agree nor disagree'=3, 'Agree'=4,
'Strongly agree'=5)
master1 <- likert2int(master1,levels = lvl1)
View(master1)
dim(master1)
##outliers using Malahanobis distance
cutoff = qchisq(1-.001, ncol(master1))
mahal = mahalanobis(master1,
colMeans(master1),
cov(master1))
mahal
cutoff ##cutoff score
ncol(master1) ##df
summary(mahal < cutoff)
##exclude outliers
noout1 = subset(master1, mahal < cutoff)
summary(noout1)
##running the efa analysis
library(psych)
library(GPArotation)
##additivity - option 1(Correlation)
correl = cor(noout1, use = "pairwise.complete.obs")
symnum(correl)
correl
##correlation adequacy Bartlett's test
cortest.bartlett(correl, n = nrow(noout1))
##sampling adequacy KMO test
KMO(correl)
##Overall MSA =  0.95 meaning
##that there are a significant number of factors in the dataset
#close to 1 which is better
##how many factors?
##how many factors?
# fm: What factor method to use.
# fm: minres, ml, uls, wls, gls, pa
# fa: show the eigen values for a principal components
# fa: you can have fa or pc, or both
nofactors = fa.parallel(noout1, fm="ml", fa="fa")
sum(nofactors$fa.values > 1.0) ##old kaiser criterion
sum(nofactors$fa.values > .7) ##new kaiser criterion
##simple structure with a two factor model
round1 = fa(noout1, nfactors=2, rotate = "oblimin", fm = "ml")
round1 #save the loading data into an excel file and check high correlation and similar correlation
#drop items that have similar correlations
#diagram
fa.diagram(round1)
round1$loadings
#Dropping variables based on communality score
drop <- c("q18b","q20b","q20d","q50b","q50c","q50d","q50h","q62f","q62i","q79b","q79c")
noout1 = noout1[,!(names(noout1) %in% drop)]
round2 = fa(noout1, nfactors=2, rotate = "oblimin", fm = "ml")
round2
fa.diagram(round2)
rm(list = ls())
##load library
library(ggplot2)
library(ca)
library("FactoMineR")
library("factoextra")
##load contigency table - 2014
aps <- read.delim("C:/Users/karishma/OneDrive/Documents/DANA/contingency_table_2014.txt",row.names=1) # read file
View(aps)
# Performing CA
aps.ca <- ca(aps)
summary(aps.ca)
aps.ca$rowcoord
aps.ca$colcoord
aps.ca$sv
plot.ca(aps.ca)
fviz_ca_biplot(aps.ca,repel=T,map="rowprincipal")
##standard ca using cacoord
standard.ca <- cacoord(aps.ca, type = "standard")
summary(standard.ca)
standard.ca
rowcoord <- standard.ca$rows
colcoord <- standard.ca$columns
rowcoord
colcoord
plot(aps.ca,main = "Standard BI-plot", arrows = c(TRUE,TRUE))
fviz_ca_biplot(aps.ca,map="standard",arrows =  c(TRUE, TRUE),title ="Standard BI-plot")
###Maximum likelihood function
MLE = function(y,n){
y/n
}
MLE(15,40)
ln(9)+1.96(0.1784)
library(PropCIs)
orscoreci(150, 300, 60, 600, conf.level = 0.95)
orscoreci(150, 150, 60, 540, conf.level = 0.95)
oddsratio(c(150,150,60,540), method = "wald", conf.level = 0.95, correction
= FALSE)
library(epitools)
oddsratio(c(150,150,60,540), method = "wald", conf.level = 0.95, correction
= FALSE)
orscoreci(150, 150, 60, 540, conf.level = 0.95)
exp^(0.7781) – 0.7640 *(0) – 0.266 * (1)
exp^(0.7781)-0.7640*(0)-0.266*(1)
exp^(0.7781)-0.7640*(0)-0.266*(1)
exp^(0.7781)-0.266
exp(0.7781)-0.266
(exp(0.7781))-0.266
0.7718-0.2666
exp(0.5052)
0.7718-0.7640-0.2666
exp(-0.2588)
(1.3279-2.7752)+(-1.308+2.4830)
exp(-0.2723)
exp(3.37843)
exp(-3.37843)
exp(-0.7640)
exp(0.7640)
pchisq((3.37843/0.20331)^2,1,lower.tail = FALSE)
pchisq(0.3439,3,lower.tail=FALSE)
happy <- read_excel("C:/Users/karishma/OneDrive/Documents/DANA/DANA_4820/Q7.xlsx")
library(readxl)
happy <- read_excel("C:/Users/karishma/OneDrive/Documents/DANA/DANA_4820/Q7.xlsx")
happy <- as.data.frame(happy)
happy
happy
m1 <- vglm(cbind(not,pretty,very) ~ as.factor(...1), family=multinomial(refLevel = "very"), data=happy)
library(VGAM)
m1 <- vglm(cbind(not,pretty,very) ~ as.factor(...1), family=multinomial(refLevel = "very"), data=happy)
m1
summary(m1)
summary(m1)
happy
#Reading the dataset
survey <- read.csv("C:/Users/karishma/OneDrive/Documents/CPSC/CPSC_4830/Final_Exam/Rshiny/survey.csv")
library('shiny')
library('tidyverse')
library('stringr')
library('shinydashboard')
library('plotly')
library('shiny')
library('shinyjs')
library("DT")
library('dplyr')
library('markdown')
library('zoo')
library('tidyr')
library(plyr)
library('plyr')
#Reading the dataset
survey <- read.csv("C:/Users/karishma/OneDrive/Documents/CPSC/CPSC_4830/Final_Exam/Rshiny/survey.csv")
head(survey)
str(survey)
glimpse(survey)
#summary
glimpse(survey)
# missing values
sapply(survey, function(x) sum(is.na(x)))
#looking at state the NA value are considered as missing.
survey$state <- survey$state %>% replace_na("NA")
# check for missing values
sapply(survey, function(x) sum(is.na(x)))
#dropping commments column
survey$comments <- NULL
#getting summary for work_interface and self_employed
summary(survey)
#checking summary for work_interface and self_employed
summary(survey)
survey$work_interfere <- survey$work_interfere %>% replace_na("NA")
survey$self_employed <- survey$self_employed %>% replace_na("NA")
# check for missing values
sapply(survey, function(x) sum(is.na(x)))
#checking accuracy for data
str(survey)
table(survey['no_employees'])
table(survey['Gender'])
#grouping the gender column
survey$Gender <- as.character(survey$Gender)
survey$Gender <- tolower(survey$Gender)
Female <- c('female', 'cis female', 'f', 'woman', 'femake', 'female ', 'cis-female/femme', 'female (cis)', 'femail')
Male <- c('m', 'male', 'male-ish', 'maile', 'cis male', 'mal', 'male (cis)',
'make', 'male ', 'man', 'msle', 'mail', 'malr', 'cis man','Mle')
Others <- c('others','a little about you','agender','androgyne','queer/she/they', 'non-binary', 'nah', 'enby', 'fluid', 'genderqueer',
'guy (-ish) ^_^', 'male leaning androgynous', 'neuter', 'queer','p','all','trans-female', 'trans woman',
'female (trans)','something kinda male?','ostensibly male, unsure what that really means')
Gender_new <- as.vector(survey$Gender)
Gender_new <- sapply(as.vector(Gender_new), function(x) if(x %in% Male) "Male" else x)
Gender_new <- sapply(as.vector(Gender_new), function(x) if(x %in% Female) "Female" else x)
Gender_new <- sapply(as.vector(Gender_new), function(x) if(x %in% Others) "Others" else x)
survey$Gender<- Gender_new
#unique value count for gender
table(survey['Gender'])
#accuracy check for numerical variables
#summary of survey
summary(survey)
#histogram
survey %>%
keep(is.numeric) %>%
gather() %>%
ggplot(aes(value)) +
facet_wrap(~ key, scales = "free") +
geom_histogram()
#histogram
plot_outlier(survey)
#outliers are in age some values are less than 0 and greater than 100, so we will drop this values.
survey<-survey[!(survey$Age<0 | survey$Age >100),]
#histogram
plot_outlier(survey)
#cleaned data
head(survey)
str(survey)
#checking null values
sum(duplicated(survey))
#filters
top_countries = c('united states of america', 'united kingdom', 'canada', 'germany', 'netherlands', 'india', 'australia', 'france', 'ireland', 'spain')
#Adding filters
top_countries = c('united states of america', 'united kingdom', 'canada', 'germany', 'netherlands', 'india', 'australia', 'france', 'ireland', 'spain')
length(top_countries)
#plots for employee
#company size vs benefits based on age
survey$no_employees <- as.factor(survey$no_employees)
survey %>%
filter(Age>21, Age<23) %>%
filter(Country %in% c('United')) %>%
filter(Gender == "Female") %>%
ggplot(aes(x = no_employees, fill = benefits)) + geom_bar(position="fill")
#plot for employee
#how company size and work type affect the mental health?
survey %>%
filter(Age>21, Age<23) %>%
filter(Gender == "Male") %>%
ggplot(aes(x=no_employees,y=treatment, fill=factor(tech_company)), color=factor(vs)) +
stat_summary(fun=mean,position=position_dodge(),geom="bar")
#plot for employeer
#people ready to seek help
survey$seek_help <- as.factor(survey$seek_help)
survey %>%
filter(Age>21, Age<23) %>%
filter(Gender == "Male" & no_employees == "100-500") %>%
ggplot(aes(x = no_employees, fill = seek_help)) + geom_bar(position = "dodge")
#plot for employeers
#Would you bring up a mental health issue with a potential employer in an interview?
survey %>%
filter(tech_company =="Yes") %>%
ggplot(aes(x=mental_health_consequence)) + geom_bar(fill = "darkgreen")
#plot for employers
#Would you bring up a mental health issue with a potential employer in an interview?
survey %>%
filter(tech_company =="Yes") %>%
ggplot(aes(x=mental_health_consequence)) + geom_bar(fill = "darkgreen")
#Would you bring up a physical health issue with a potential employer in an interview?
survey %>%
filter(tech_company =="Yes") %>%
ggplot(aes(x=phys_health_consequence)) + geom_bar(fill = "darkgreen")
#plot for employeers
#Does promising Anonymity encourage employees to seek treatment for mental health?
survey %>%
filter(Age>21, Age<23) %>%
filter(Gender == "Male") %>%
ggplot(aes(x = anonymity, fill = treatment)) + geom_bar(position = "dodge")
freqtable <- table(survey$Country)
Country1 <- as.data.frame.table(freqtable)
world <-joinCountryData2Map(Country1, joinCode="NAME", nameJoinColumn="Var1")
mapCountryData(world,nameColumnToPlot = "Freq",
mapTitle = "Distribution of Participants by country")
g <- list(
scope = 'usa',
projection = list(type = 'albers usa'),
lakecolor = toRGB('yellow')
)
plot_ly(z = survey$treatment,
locations = survey$Country,
type = 'choropleth',
color = survey$mental_health_interview,
locationmode = 'USA-states') %>%
layout(geo = g,title = paste0("Map of crimes in US in year: "))
se_df <- load_cat(survey %>%
select(Gender) %>%
group_by(Gender))
se_df <- load_cat(survey %>%
select(Gender_new) %>%
group_by(Gender_new))
library(viridisLite)
library(cowplot)
library(treemap)
library(tm)
library(wordcloud)
library(RColorBrewer)
library(maps)
library(countrycode)
library(purrr)
library(htmltools)
se_df <- load_cat(survey %>%
select(Gender_new) %>%
group_by(Gender_new))
se_df <- survey %>%
select(treatment, Gender_new) %>%
group_by(treatment, Gender_new) %>%
summarize(count = n()) %>%
mutate(percentage = paste0(round(count / sum(count) * 100, 1), "%"))
# Group by Age Group and count each group
library(dplyr)
age_group <-survey%>%
group_by(Age) %>%
dplyr::summarize(count = n())
age_group
# Visualize the number of subjects in each Age Group
ggplot(age_group, aes(x = Age, y = count, fill = Age)) +
geom_bar(stat = "identity", alpha = 0.5) +
xlab("Age Group") +
ylab("No of People") +
ggtitle("Comparing Age Group in the 2014 Mental Health in Tech Survey")
# First, re-value the variables of interest
survey$no_employees <- as.factor(revalue(survey$no_employees,
c("1-5"="1", "6-25"="2", "26-100"="3", "100-500"="4", "500-1000"="5", "More than 1000"="6")))
survey$treatment <- as.numeric(revalue(survey$treatment,
c("No"="0", "Yes"="1")))
# Use a bar graph to graph `treatment` (treated mental health condition) over `no_employees` (number of employees) and `tech_company` (company type)
ggplot(survey,aes(x=no_employees,y=treatment, fill=factor(tech_company)), color=factor(vs)) +
stat_summary(fun.y=mean,position=position_dodge(),geom="bar") +
labs(x = "Number of employees", y = "Probability of mental health condition",
title = "Probability of mental health illness by workplace type and size") +
scale_x_discrete(labels=c("1" = "1-5", "2" = "6-25", "3" = "26-100", "4"="100-500", "5"="500-1000", "6"=">1000"))
# Use a bar graph to graph `treatment` (treated mental health condition) over `no_employees` (number of employees) and `tech_company` (company type)
ggplot(survey,aes(x=no_employees,y=treatment, fill=factor(tech_company)), color=factor(vs)) +
stat_summary(fun.y=mean,position=position_dodge(),geom="bar") +
labs(x = "Number of Employees", y = "Probability of mental health condition",
title = "Probability of mental health illness by Workplace type and size") +
scale_x_discrete(labels=c("1" = "1-5", "2" = "6-25", "3" = "26-100", "4"="100-500", "5"="500-1000", "6"=">1000"))
# Use a bar graph to graph `treatment` (treated mental health condition) over `no_employees` (number of employees) and `tech_company` (company type)
ggplot(survey,aes(x=no_employees,y=treatment, fill=factor(tech_company)), color=factor(vs)) +
stat_summary(fun=mean,position=position_dodge(),geom="bar") +
labs(x = "Number of Employees", y = "Probability of mental health condition",
title = "Probability of mental health illness by Workplace type and size") +
scale_x_discrete(labels=c("1" = "1-5", "2" = "6-25", "3" = "26-100", "4"="100-500", "5"="500-1000", "6"=">1000"))
#plots for employee
#company size vs benefits based on age
survey$no_employees <- as.factor(survey$no_employees)
survey %>%
filter(Age>21, Age<23) %>%
filter(Country %in% c('United')) %>%
filter(Gender == "Female") %>%
ggplot(aes(x = no_employees, fill = benefits)) + geom_bar(position="fill")
#plot for employee
#how company size and work type affect the mental health?
survey %>%
filter(Age>21, Age<23) %>%
filter(Gender == "Male") %>%
ggplot(aes(x=no_employees,y=treatment, fill=factor(tech_company)), color=factor(vs)) +
stat_summary(fun=mean,position=position_dodge(),geom="bar")
#plot for employeer
#people ready to seek help
survey$seek_help <- as.factor(survey$seek_help)
survey %>%
filter(Age>21, Age<23) %>%
filter(Gender == "Male" & no_employees == "100-500") %>%
ggplot(aes(x = no_employees, fill = seek_help)) + geom_bar(position = "dodge")
#plot for employers
#Would you bring up a mental health issue with a potential employer in an interview?
survey %>%
filter(tech_company =="Yes") %>%
ggplot(aes(x=mental_health_consequence)) + geom_bar(fill = "darkgreen")
#plot for employers
#Would you bring up a mental health issue with a potential employer in an interview?
survey %>%
filter(tech_company =="Yes") %>%
ggplot(aes(x=mental_health_consequence)) + geom_bar(fill = "darkgreen")
#Would you bring up a physical health issue with a potential employer in an interview?
survey %>%
filter(tech_company =="Yes") %>%
ggplot(aes(x=phys_health_consequence)) + geom_bar(fill = "darkgreen")
#Would you bring up a physical health issue with a potential employer in an interview?
survey %>%
filter(tech_company =="Yes") %>%
ggplot(aes(x=phys_health_consequence)) + geom_bar(fill = "purple")
#plot for employers
#Would you bring up a mental health issue with a potential employer in an interview?
survey %>%
filter(tech_company =="Yes") %>%
ggplot(aes(x=mental_health_consequence)) + geom_bar(fill = "darkblue")
#Would you bring up a physical health issue with a potential employer in an interview?
survey %>%
filter(tech_company =="Yes") %>%
ggplot(aes(x=phys_health_consequence)) + geom_bar(fill = "blue")
#Would you bring up a physical health issue with a potential employer in an interview?
survey %>%
filter(tech_company =="Yes") %>%
ggplot(aes(x=phys_health_consequence)) + geom_bar(fill = "darkblue")
#plot for employeers
#Does promising Anonymity encourage employees to seek treatment for mental health?
survey %>%
filter(Age>21, Age<23) %>%
filter(Gender == "Male") %>%
ggplot(aes(x = anonymity, fill = treatment)) + geom_bar(position = "dodge")
runApp('CPSC/CPSC_4830/Final_Exam/Rshiny')
runApp('CPSC/CPSC_4830/Final_Exam/Rshiny')
runApp('CPSC/CPSC_4830/Final_Exam/Rshiny')
runApp('CPSC/CPSC_4830/Final_Exam/Rshiny')
runApp('CPSC/CPSC_4830/Final_Exam/Rshiny')
runApp('CPSC/CPSC_4830/Final_Exam/Rshiny')
runApp('CPSC/CPSC_4830/Final_Exam/Rshiny')
runApp('CPSC/CPSC_4830/Final_Exam/Rshiny')
runApp('CPSC/CPSC_4830/Final_Exam/Rshiny')
age_group <-survey%>%
group_by(Age) %>%
dplyr::summarize(count = n())
age_group
runApp('CPSC/CPSC_4830/Final_Exam/R_Shiny')
runApp('CPSC/CPSC_4830/Final_Exam/R_Shiny')
runApp('CPSC/CPSC_4830/Final_Exam/R_Shiny')
runApp('CPSC/CPSC_4830/Final_Exam/R_Shiny')
runApp('CPSC/CPSC_4830/Final_Exam/R_Shiny')
runApp('CPSC/CPSC_4830/Final_Exam/R_Shiny')
runApp('CPSC/CPSC_4830/Final_Exam/R_Shiny')
runApp('CPSC/CPSC_4830/Final_Exam/R_Shiny')
write.csv(survey,"C:/Users/karishma/OneDrive/Documents/CPSC/CPSC_4830/Final_Exam/Rshiny/survey_updated.csv")
runApp('CPSC/CPSC_4830/Final_Exam/R_Shiny')
runApp('CPSC/CPSC_4830/Final_Exam/R_Shiny')
runApp('CPSC/CPSC_4830/Final_Exam/R_Shiny')
